# -*- coding: utf-8 -*-
"""Exp8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NLsWcFP4Qv4VHSHQetsWTpMILjLcS1q7
"""

!pip install pandas scikit-learn shap streamlit fastapi uvicorn joblib evidently pyngrok matplotlib

!pip install pyngrok

!pip install streamlit pyngrok shap matplotlib pandas scikit-learn

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# # =========================================
# # Responsible AI Dashboard ‚Äî Full Working Code (improved)
# # =========================================
# 
# import streamlit as st
# import pandas as pd
# import numpy as np
# import joblib
# import shap
# import matplotlib.pyplot as plt
# from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
# from scipy.stats import ks_2samp
# 
# st.set_page_config(page_title="Responsible AI Dashboard", layout="wide")
# st.title("üìä Responsible AI Dashboard ‚Äî Predictions & Insights")
# 
# TARGET_COL = "delivery_speed_category"
# 
# # --- Load Trained Model ---
# @st.cache_resource
# def load_model(path="model.pkl"):
#     return joblib.load(path)
# 
# model = load_model()
# preprocessor = model.named_steps["preprocessor"]
# regressor = model.named_steps["regressor"]
# 
# # =========================
# # Helper: Clean feature names
# # =========================
# def get_clean_feature_names(preprocessor, input_X=None):
#     """
#     Attempt to derive feature names from the preprocessor. If that fails,
#     and input_X (DataFrame) is provided, fallback to input_X.columns.
#     """
#     feature_names = []
#     try:
#         for name, transformer, cols in preprocessor.transformers_:
#             if name == 'remainder' and transformer == 'drop':
#                 continue
#             # If transformer is a pipeline, look at final step
#             if hasattr(transformer, 'named_steps'):
#                 last_step = transformer.named_steps[list(transformer.named_steps.keys())[-1]]
#                 if hasattr(last_step, 'get_feature_names_out'):
#                     names = last_step.get_feature_names_out(cols)
#                 else:
#                     names = cols
#             elif hasattr(transformer, 'get_feature_names_out'):
#                 names = transformer.get_feature_names_out(cols)
#             else:
#                 names = cols
#             # Some transformers return numpy arrays of names or lists
#             if isinstance(names, (list, np.ndarray)):
#                 feature_names.extend(list(names))
#             else:
#                 feature_names.append(str(names))
#         # strip common prefixes like "num__" or "cat__"
#         clean_names = [n.split("__")[-1] if "__" in str(n) else str(n) for n in feature_names]
#         return clean_names
#     except Exception:
#         # fallback
#         if input_X is not None:
#             return list(input_X.columns)
#         return []
# 
# # =========================
# # 1Ô∏è‚É£ Dashboard for Predictions & Insights
# # =========================
# st.subheader("Upload CSV for Prediction")
# uploaded_file = st.file_uploader("Choose a CSV file", type="csv")
# if uploaded_file is None:
#     st.warning("No file uploaded. Please upload a CSV file to start.")
#     st.stop()
# 
# # Read the uploaded file
# data = pd.read_csv(uploaded_file)
# st.write("### Uploaded Data Preview")
# st.dataframe(data.head())
# 
# # Prepare features for prediction (drop target if present)
# X = data.drop(columns=[TARGET_COL], errors="ignore").copy()
# 
# # Fit preprocessor.transform on X (we assume preprocessor was fit during training)
# try:
#     X_transformed = preprocessor.transform(X)
# except Exception as e:
#     st.error(f"Error transforming uploaded data with preprocessor: {e}")
#     st.stop()
# 
# # If sparse matrix, convert to dense
# if hasattr(X_transformed, "toarray"):
#     X_transformed = X_transformed.toarray()
# # ensure numeric dtype for model predict
# X_transformed = X_transformed.astype(np.float64)
# 
# # Make predictions
# try:
#     preds = regressor.predict(X_transformed)
# except Exception as e:
#     st.error(f"Error making predictions with regressor: {e}")
#     st.stop()
# 
# data["Predictions"] = preds
# st.write("### Predictions Added")
# st.dataframe(data.head())
# 
# # =========================
# # 2Ô∏è‚É£ SHAP Plots
# # =========================
# st.subheader("üí° SHAP Feature Importance")
# 
# # Try to get feature names for the transformed matrix. If that fails, generate generic names.
# feature_names = get_clean_feature_names(preprocessor, input_X=X)
# # If the transformer expanded features (e.g., one-hot), number of names may not match columns.
# if len(feature_names) != X_transformed.shape[1]:
#     # fallback to generic names like f"f0, f1..."
#     feature_names = [f"f{i}" for i in range(X_transformed.shape[1])]
# 
# # Convert transformed data to DataFrame for nicer SHAP plotting (if possible)
# X_trans_df = pd.DataFrame(X_transformed, columns=feature_names)
# 
# # Create SHAP explainer (try TreeExplainer first; fallback to KernelExplainer if needed)
# try:
#     explainer = shap.TreeExplainer(regressor)
#     shap_values = explainer.shap_values(X_trans_df)
# except Exception:
#     try:
#         explainer = shap.Explainer(regressor, X_trans_df)
#         shap_values = explainer(X_trans_df).values
#     except Exception as e:
#         st.warning(f"Could not create SHAP explainer: {e}")
#         shap_values = None
# 
# if shap_values is not None:
#     # If shap_values is list (multi-output), try to select the right array
#     if isinstance(shap_values, list) and len(shap_values) > 0:
#         # pick first output (common for single-output regressors returning list)
#         shap_arr = shap_values[0]
#     else:
#         shap_arr = shap_values
# 
#     # If shap_arr is an Explanation object (from newer shap), extract .values
#     if hasattr(shap_arr, "values"):
#         shap_arr = shap_arr.values
# 
#     try:
#         # Global importance (bar)
#         fig, ax = plt.subplots(figsize=(8, 5))
#         shap.summary_plot(shap_arr, X_trans_df, feature_names=feature_names, plot_type="bar", show=False)
#         st.pyplot(fig, clear_figure=True)
# 
#         # Detailed summary (dot)
#         fig2, ax2 = plt.subplots(figsize=(10, 6))
#         shap.summary_plot(shap_arr, X_trans_df, feature_names=feature_names, show=False)
#         st.pyplot(fig2, clear_figure=True)
#     except Exception as e:
#         st.warning(f"Error plotting SHAP summary: {e}")
# else:
#     st.info("SHAP values unavailable for this model type. Skipping SHAP plots.")
# 
# # =========================
# # 3Ô∏è‚É£ Metrics
# # =========================
# st.subheader("üìà Model Performance Metrics")
# if TARGET_COL in data.columns:
#     y_true = data[TARGET_COL]
# 
#     # Map categorical target to numeric if needed
#     if y_true.dtype == object:
#         mapping = {"Slow": 0, "Medium": 1, "Fast": 2}
#         y_true = y_true.map(mapping)
# 
#     mask = (~pd.isna(y_true)) & (~pd.isna(preds))
#     y_true_clean = np.nan_to_num(y_true[mask].astype(float))
#     preds_clean = np.nan_to_num(preds[mask].astype(float))
# 
#     if len(y_true_clean) > 1:
#         r2 = r2_score(y_true_clean, preds_clean)
#         mae = mean_absolute_error(y_true_clean, preds_clean)
#         mse = mean_squared_error(y_true_clean, preds_clean)
#         rmse = np.sqrt(mse)
#         metrics_df = pd.DataFrame({
#             "Metric": ["R¬≤ Score", "MAE", "MSE", "RMSE"],
#             "Value": [r2, mae, mse, rmse]
#         })
#         st.dataframe(metrics_df)
#     else:
#         st.warning("Not enough valid rows to compute metrics.")
# 
# # =========================
# # 4Ô∏è‚É£ Drift Checks (Improved)
# # =========================
# st.subheader("üö¶ Drift Detection (KS Test)")
# 
# try:
#     # Load baseline training sample
#     baseline = pd.read_csv("train_data_sample.csv")
# 
#     # Select numeric columns in both baseline and uploaded data
#     numeric_baseline = baseline.select_dtypes(include=[np.number])
#     numeric_uploaded = X.select_dtypes(include=[np.number]).fillna(0)
# 
#     # Find common numeric columns
#     common_cols = numeric_baseline.columns.intersection(numeric_uploaded.columns)
# 
#     if len(common_cols) == 0:
#         st.warning("No numeric columns match between baseline and uploaded data for drift detection.")
#     else:
#         drift_rows = []
#         for col in common_cols:
#             a = numeric_baseline[col].dropna()
#             b = numeric_uploaded[col].dropna()
# 
#             # KS test only if enough data
#             if len(a) < 5 or len(b) < 5:
#                 p_val = np.nan
#                 drift_flag = "Insufficient data"
#             else:
#                 stat, p_val = ks_2samp(a, b)
#                 drift_flag = "Yes" if (p_val < 0.05) else "No"
# 
#             # Format p-value nicely (or N/A)
#             p_display = f"{round(p_val, 4):.4f}" if not np.isnan(p_val) else "N/A"
# 
#             drift_rows.append({
#                 "Feature": col,
#                 "KS P-value": p_display,
#                 "Drift Detected": drift_flag
#             })
# 
#         # Display table
#         drift_df = pd.DataFrame(drift_rows)
#         st.dataframe(drift_df)
# 
# except FileNotFoundError:
#     st.warning("Baseline training data not found. Upload `train_data_sample.csv` for drift checks.")
#

!ngrok authtoken 33h7jsM08P3XwGH254ef6naiVN5_7LmmQ3ztGTffYvL8uuBSB

from pyngrok import ngrok
import os

# Run Streamlit in background
get_ipython().system_raw("streamlit run app.py &")

# Open public URL
public_url = ngrok.connect(8501)
print("üåê Your Streamlit dashboard is live at:", public_url)

!pkill -f ngrok